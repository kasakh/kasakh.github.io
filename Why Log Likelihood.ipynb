{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Tex macros - don't touch\n",
    "$$ \n",
    "\\def\\R{{\\mathbb R}} \n",
    "\\newcommand{\\tbrkt}[1]{(#1)}\n",
    "\\newcommand{\\mbrkt}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\vecuc}{\\mathbf{U}}\n",
    "\\newcommand{\\vecu}{\\mathbf{u}}\n",
    "\\newcommand{\\vecx}{\\mathbf{x}}\n",
    "\\newcommand{\\vecs}{\\mathbf{S}}\n",
    "\\newcommand{\\vecz}{\\mathbf{z}}\n",
    "\\newcommand{\\vecy}{\\mathbf{y}}\n",
    "\\newcommand{\\vecY}{\\mathbf{Y}}\n",
    "\\def\\ba{\\mathbf{a}}\n",
    "\\def\\bb{\\mathbf{b}}\n",
    "\\def\\be{\\mathbf{e}}\n",
    "\\def\\bx{\\mathbf{x}}\n",
    "\\def\\by{\\mathbf{y}}\n",
    "\\def\\bz{\\mathbf{z}}\n",
    "\\def\\bc{\\mathbf{c}}\n",
    "\\def\\bm{\\mathbf{m}}\n",
    "\\def\\bt{\\mathbf{t}}\n",
    "\\def\\bv{\\mathbf{v}}\n",
    "\\def\\bu{\\mathbf{u}}\n",
    "\\def\\bw{\\mathbf{w}}\n",
    "\\def\\bF{\\mathbf{F}}\n",
    "\\def\\bJ{\\mathbf{J}}\n",
    "\\def\\bA{\\mathbf{A}}\n",
    "\\def\\bH{\\mathbf{H}}\n",
    "\\def\\bT{\\mathbf{T}}\n",
    "\\def\\bX{\\mathbf{X}}\n",
    "\\def\\bY{\\mathbf{Y}}\n",
    "\\def\\bW{\\mathbf{W}}\n",
    "\\def\\bB{\\mathbf{B}}\n",
    "\\def\\bD{\\mathbf{D}}\n",
    "\\def\\bS{\\mathbf{S}}\n",
    "\\def\\bI{\\mathbf{I}}\n",
    "\\def\\bL{\\mathbf{L}}\n",
    "\\def\\bU{\\mathbf{U}}\n",
    "\\def\\bV{\\mathbf{V}}\n",
    "\\def\\bZ{\\mathbf{Z}}\n",
    "\\def\\b0{\\mathbf{0}}\n",
    "\\def\\b1{\\mathbf{1}}\n",
    "\\def\\cC{\\mathcal{C}}\n",
    "\\def\\cD{\\mathcal{D}}\n",
    "\\def\\cE{\\mathcal{E}}\n",
    "\\def\\cL{\\mathcal{L}}\n",
    "\\def\\cN{\\mathcal{N}}\n",
    "\\def\\cO{\\mathcal{O}}\n",
    "\\def\\cU{\\mathcal{U}}\n",
    "\\def\\cX{\\mathcal{X}}\n",
    "\\def\\cW{\\mathcal{W}}\n",
    "\\def\\mR{\\mathbb{R}}\n",
    "\\def\\mN{\\mathbb{N}}\n",
    "\\def\\EE{\\mathbb{E}}\n",
    "\\def\\btheta{\\mathbf{\\theta}}\n",
    "\\def\\bvartheta{\\mbox{\\boldmath $\\vartheta$}}\n",
    "\\def\\bomega{\\mbox{\\boldmath $\\omega$}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use Log Likelihood instead of Likelihood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that likelihood usually enters the ML pipeline as the -ve of the cost function i.e. maximizing the likelihood corresponds to minimizing the cost function. In fact, [most cost functions are some form of likelihoods](https://datascience.stackexchange.com/q/10188/38717).  E.g. In linear regression, the squared error loss directly comes from the assumption of Gaussian error. Similarly, the cross entropy loss used in logistic regression directly comes from the Bernoulli distribution. Thus, likelihood plays an important role in almost all ML problems. Here we take a closer look at why we try to work with **log likelihood instead of likelihood**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence assumption\n",
    "1. Given $n$ datapoints $\\bX = (x_1,x_2,\\dots,x_n)$ which are sampled **independently sampled from the same distribution** $f(.,\\btheta)$, we usually want to make some inference about the parameters $\\theta$ of the distribution. E.g. $f$ could be a Gaussian distribution and we want to estimate its parameters - mean $\\theta_1$ and variance $\\theta_2$.  One of the widely used approaches to make inference is to finding parameters that maximize the probability that we observe the given data $\\bX$ - This procedure is also known as [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation). \n",
    "The likelihood of observing the data under the **independence** setting is given by $f(x_1,\\btheta)f(x_2,\\btheta)\\dots f(x_n,\\btheta)$. Maximizing this product expression with respect to $\\btheta$ would be cumbersome even if the density $f$ has a simple expression such as polynomial  (as we have to compute $\\frac{\\partial f(x_1,\\btheta)}{\\partial \\btheta}f(x_2,\\btheta)\\dots f(x_n,\\btheta) + f(x_1,\\btheta) \\frac{\\partial f(x_2,\\btheta)}{\\partial \\btheta} \\dots f(x_n,\\btheta) + \\dots + f(x_1,\\btheta)\\dots f(x_{n-1},\\btheta)\\frac{\\partial f(x_n,\\btheta)}{\\partial \\btheta}  $). However, most real-world probability densities have much more complicated expressions which makes this maximization almost intractable. Taking a logarithm of this product helps with the tractability. \n",
    "Since log is monotonically increasing, the same $\\btheta^{*}$ which maximizes the product expression would also maximize the $\\log (f(x_1,\\btheta)f(x_2,\\btheta)\\dots f(x_n,\\btheta)) = \\sum_i \\log f(x_i,\\btheta)$. Evaluating the gradient expression with this log likelihood is much more easy to handle (as we have to just evaluate $\\sum_i \\frac{1}{f(x_i,\\btheta)}\\frac{\\partial f(x_i,\\btheta)}{\\partial \\btheta}$ which does not involve any product terms. Further this gradient can be computed *in parallel* by considering batches of the input datapoints, which cannot be done in the product expression above. **This is a big deal especially when we are dealing with thousands of datapoints.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most densities are from the exponential family\n",
    "2. Most densities we encounter in day-to-day applications come from the [exponential family](https://en.wikipedia.org/wiki/Exponential_family) - e.g. Gaussian, Binomial, Bernoulli, Dirichlet, Poisson, etc. The general form of density of exponential family distributions is given by\n",
    "\n",
    "$f_X(x,\\btheta) = h(x)\\,\\exp\\!\\bigl[\\,\\eta(\\btheta) \\cdot T(x) +A(\\btheta)\\,\\bigr]$, where $h,\\eta,A,T$ are known functions - e.g. For the Gaussian distribution $f(x;\\mu,\\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}$, we have\n",
    "\n",
    "\\begin{align} \n",
    "\\boldsymbol {\\eta} &= \\left[\\,\\frac{\\mu}{\\sigma^2},~-\\frac{1}{2\\sigma^2}\\,\\right]^{\\mathsf T} \\\\\n",
    "h(x) &= \\frac{1}{\\sqrt{2 \\pi}} \\\\\n",
    "T(x) &= \\left( x, x^2 \\right)^{\\rm T} \\\\\n",
    "A({\\boldsymbol \\eta}) &= \\frac{\\mu^2}{2 \\sigma^2} + \\log |\\sigma| = -\\frac{\\eta_1^2}{4\\eta_2} + \\frac{1}{2}\\log\\left|\\frac{1}{2\\eta_2} \\right|\n",
    "\\end{align}\n",
    "\n",
    "Hence, when dealing with most real-world distributions, it makes sense to take the logarithm which can cancel the exponential in the density expression, thereby yielding a much simpler gradient expression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Computational issues\n",
    "3. Consider the scenario where we have 1000 datapoints sampled from a standard Normal distribution. Try evaluating the product of their densities $f(x_1,\\btheta)f(x_2,\\btheta)\\dots f(x_n,\\btheta)$ where each density term can range from the order of $10^{-1}$ to $10^{-3}$; it would be a very small number, close to zero.  If one were not careful, the machine would do a crude approximation of the very small number to zero. Evaluating the gradients when the absolute value of the objective is so small can lead to errors. However, considering the log likelihood $\\sum_i \\log f(x_i,\\btheta)$, the individual terms in this summation are of large enough magnitude (usually with a -ve sign) and hence no such approximation errors occur. I have burnt my fingers more than once with this approximation of very small densities to zeros. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
